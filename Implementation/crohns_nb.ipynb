{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.decomposition import NMF\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.ensemble import RandomForestClassifier,VotingClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import precision_score,accuracy_score,f1_score,recall_score,confusion_matrix\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.linear_model import LogisticRegression,Lasso\n",
    "from mlxtend.feature_selection import ColumnSelector\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier,ExtraTreesClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "# from sklearn.feature_selection import SelectPercent\n",
    "import pickle, joblib\n",
    "from sklearn.preprocessing import KBinsDiscretizer, PowerTransformer, QuantileTransformer,RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irfan\\AppData\\Local\\Temp\\ipykernel_17416\\1647319165.py:2: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_merged=pd.read_csv('merged.csv',header=None,index_col=False)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gene</th>\n",
       "      <th>SEC24B-AS1</th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>GGACT</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A2MP1</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>...</th>\n",
       "      <th>RNF213</th>\n",
       "      <th>SFMBT1</th>\n",
       "      <th>ERCC-00031</th>\n",
       "      <th>ERCC-00042</th>\n",
       "      <th>ERCC-00069</th>\n",
       "      <th>ERCC-00084</th>\n",
       "      <th>ERCC-00097</th>\n",
       "      <th>ERCC-00112</th>\n",
       "      <th>ERCC-00131</th>\n",
       "      <th>ERCC-00136</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2211090011-PBMC</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>826.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2211160007-PBMC</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>678.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2210050025-PBMC</td>\n",
       "      <td>14</td>\n",
       "      <td>78</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>2185</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>403.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2211150016-PBMC</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>861.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2211150008-PBMC</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>378.0</td>\n",
       "      <td>244.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>2211160008-PBMC</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>853.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>2307270005-PBMC</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>2555</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>2307260014-PBMC</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>4374</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>2307260036-PBMC</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>4827</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Majeed-Sabeera-PBMC</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>4963</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135 rows × 20783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Gene SEC24B-AS1 A1BG A1CF GGACT   A2M A2ML1 A2MP1 A4GALT  \\\n",
       "1        2211090011-PBMC          2    2    0     5    13     0     0      0   \n",
       "2        2211160007-PBMC          7    1    0     4     1     0     1      0   \n",
       "3        2210050025-PBMC         14   78   68     0  2185     0     1     76   \n",
       "4        2211150016-PBMC          1    3    0     3     1     0     2      0   \n",
       "5        2211150008-PBMC          2    3    0     0     3     0     0      1   \n",
       "..                   ...        ...  ...  ...   ...   ...   ...   ...    ...   \n",
       "131      2211160008-PBMC          5    0    0     0     5     0     1      0   \n",
       "132      2307270005-PBMC          5    1    0     3    13     0     2      1   \n",
       "133      2307260014-PBMC          7    0    0     3    24     0     2      1   \n",
       "134      2307260036-PBMC          5    1    0     4    26     0     4      1   \n",
       "135  Majeed-Sabeera-PBMC          6    2    0     5    35     0     1      0   \n",
       "\n",
       "    A4GNT  ... RNF213 SFMBT1 ERCC-00031 ERCC-00042 ERCC-00069 ERCC-00084  \\\n",
       "1       0  ...  826.0   46.0        0.0        0.0        0.0        0.0   \n",
       "2       0  ...  678.0   32.0        0.0        0.0        0.0        0.0   \n",
       "3       0  ...  403.0  101.0        0.0        0.0        0.0        0.0   \n",
       "4       0  ...  861.0   37.0        0.0        0.0        0.0        0.0   \n",
       "5       1  ...  378.0  244.0        0.0        0.0        0.0        0.0   \n",
       "..    ...  ...    ...    ...        ...        ...        ...        ...   \n",
       "131     0  ...  853.0   21.0        0.0        0.0        0.0        0.0   \n",
       "132     0  ...      0      0         20          0          0          0   \n",
       "133     0  ...      0      0         35          0          0          0   \n",
       "134     0  ...      0      0         50          0          0          0   \n",
       "135     0  ...      1      0         21          0          0          0   \n",
       "\n",
       "    ERCC-00097 ERCC-00112 ERCC-00131 ERCC-00136  \n",
       "1          0.0        0.0        0.0        0.0  \n",
       "2          0.0        0.0        0.0        0.0  \n",
       "3          0.0        0.0        0.0        0.0  \n",
       "4          0.0        0.0        0.0        0.0  \n",
       "5          0.0        0.0        0.0        0.0  \n",
       "..         ...        ...        ...        ...  \n",
       "131        0.0        0.0        0.0        0.0  \n",
       "132         63       2555          0          6  \n",
       "133         41       4374          0         10  \n",
       "134         43       4827          0         14  \n",
       "135         54       4963          0          4  \n",
       "\n",
       "[135 rows x 20783 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In house Dataset\n",
    "data_merged=pd.read_csv('merged.csv',header=None,index_col=False)\n",
    "\n",
    "data_merged_2=data_merged.iloc[:20783]\n",
    "\n",
    "data_merged_2=pd.DataFrame.transpose(data_merged_2)\n",
    "\n",
    "data_merged_2.columns=data_merged_2.iloc[0].values\n",
    "data_merged_2=data_merged_2.tail(-1)\n",
    "\n",
    "\n",
    "\n",
    "data_merged_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_merged_2.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcomes</th>\n",
       "      <th>ITGB2</th>\n",
       "      <th>ABCG2</th>\n",
       "      <th>MMP2</th>\n",
       "      <th>IFNG</th>\n",
       "      <th>CXCL12</th>\n",
       "      <th>HPGDS</th>\n",
       "      <th>FN1</th>\n",
       "      <th>CYP2B6</th>\n",
       "      <th>ADH1A</th>\n",
       "      <th>...</th>\n",
       "      <th>CXCL10</th>\n",
       "      <th>HSD17B2</th>\n",
       "      <th>IL1B</th>\n",
       "      <th>IL6</th>\n",
       "      <th>SLC51A</th>\n",
       "      <th>MMP9</th>\n",
       "      <th>PPARG</th>\n",
       "      <th>FCGR3A</th>\n",
       "      <th>NR1H4</th>\n",
       "      <th>CD44</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "      <td>31897</td>\n",
       "      <td>0</td>\n",
       "      <td>1255</td>\n",
       "      <td>0</td>\n",
       "      <td>1027006</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>564</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1201</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>133</td>\n",
       "      <td>26183</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>467407</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1008</td>\n",
       "      <td>7</td>\n",
       "      <td>226</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>1069</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>23428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>15</td>\n",
       "      <td>58028</td>\n",
       "      <td>0</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>573809</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>20</td>\n",
       "      <td>753</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>837</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>10936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>38045</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>236591</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>267</td>\n",
       "      <td>2079</td>\n",
       "      <td>7136</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>926</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>12021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>26</td>\n",
       "      <td>48239</td>\n",
       "      <td>0</td>\n",
       "      <td>1550</td>\n",
       "      <td>0</td>\n",
       "      <td>435965</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>95</td>\n",
       "      <td>12</td>\n",
       "      <td>298</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>998</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>16665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>24710</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>3</td>\n",
       "      <td>1600799</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>1119</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>22032</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "      <td>564610</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>905</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>20913</td>\n",
       "      <td>0</td>\n",
       "      <td>993</td>\n",
       "      <td>0</td>\n",
       "      <td>881463</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>392</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>815</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>22709</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>808555</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>473</td>\n",
       "      <td>82</td>\n",
       "      <td>2</td>\n",
       "      <td>2026</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>9103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>19557</td>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>1319261</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>46</td>\n",
       "      <td>1104</td>\n",
       "      <td>59</td>\n",
       "      <td>1</td>\n",
       "      <td>1106</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>15177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>14580</td>\n",
       "      <td>0</td>\n",
       "      <td>503</td>\n",
       "      <td>0</td>\n",
       "      <td>887571</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>198</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>952</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>6778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>8372</td>\n",
       "      <td>0</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>427432</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>360</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "      <td>1605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>20140</td>\n",
       "      <td>0</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>1125199</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>173</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>854</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>16721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>20</td>\n",
       "      <td>44296</td>\n",
       "      <td>0</td>\n",
       "      <td>1685</td>\n",
       "      <td>0</td>\n",
       "      <td>614962</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>16</td>\n",
       "      <td>545</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>14025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>23</td>\n",
       "      <td>32153</td>\n",
       "      <td>0</td>\n",
       "      <td>1030</td>\n",
       "      <td>0</td>\n",
       "      <td>601137</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>11</td>\n",
       "      <td>990</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>726</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "      <td>68807</td>\n",
       "      <td>0</td>\n",
       "      <td>5705</td>\n",
       "      <td>1</td>\n",
       "      <td>895780</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>367</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>11475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>44515</td>\n",
       "      <td>0</td>\n",
       "      <td>901</td>\n",
       "      <td>0</td>\n",
       "      <td>193947</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>724</td>\n",
       "      <td>334</td>\n",
       "      <td>1196</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>19673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>23</td>\n",
       "      <td>21588</td>\n",
       "      <td>0</td>\n",
       "      <td>1441</td>\n",
       "      <td>0</td>\n",
       "      <td>1167185</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "      <td>2</td>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>1</td>\n",
       "      <td>1410</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>56925</td>\n",
       "      <td>0</td>\n",
       "      <td>2570</td>\n",
       "      <td>0</td>\n",
       "      <td>530117</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>573</td>\n",
       "      <td>38</td>\n",
       "      <td>4</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>11263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>52952</td>\n",
       "      <td>0</td>\n",
       "      <td>658</td>\n",
       "      <td>0</td>\n",
       "      <td>549530</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>903</td>\n",
       "      <td>66</td>\n",
       "      <td>4</td>\n",
       "      <td>1058</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>13355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>39</td>\n",
       "      <td>55173</td>\n",
       "      <td>0</td>\n",
       "      <td>1162</td>\n",
       "      <td>0</td>\n",
       "      <td>188531</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>860</td>\n",
       "      <td>427</td>\n",
       "      <td>1459</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>483</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>33</td>\n",
       "      <td>53755</td>\n",
       "      <td>0</td>\n",
       "      <td>1608</td>\n",
       "      <td>0</td>\n",
       "      <td>379301</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>68</td>\n",
       "      <td>65</td>\n",
       "      <td>257</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>818</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>47742</td>\n",
       "      <td>0</td>\n",
       "      <td>957</td>\n",
       "      <td>0</td>\n",
       "      <td>432017</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>13</td>\n",
       "      <td>995</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>761</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>18256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>41991</td>\n",
       "      <td>0</td>\n",
       "      <td>284</td>\n",
       "      <td>0</td>\n",
       "      <td>538509</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>322</td>\n",
       "      <td>77</td>\n",
       "      <td>1</td>\n",
       "      <td>946</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>7985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>55573</td>\n",
       "      <td>0</td>\n",
       "      <td>127</td>\n",
       "      <td>0</td>\n",
       "      <td>250661</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>773</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "      <td>934</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>215</td>\n",
       "      <td>17995</td>\n",
       "      <td>32</td>\n",
       "      <td>431</td>\n",
       "      <td>40</td>\n",
       "      <td>400690</td>\n",
       "      <td>224</td>\n",
       "      <td>135</td>\n",
       "      <td>...</td>\n",
       "      <td>52</td>\n",
       "      <td>96</td>\n",
       "      <td>69</td>\n",
       "      <td>189</td>\n",
       "      <td>215</td>\n",
       "      <td>239</td>\n",
       "      <td>477</td>\n",
       "      <td>196</td>\n",
       "      <td>128</td>\n",
       "      <td>17585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>58</td>\n",
       "      <td>70283</td>\n",
       "      <td>0</td>\n",
       "      <td>2204</td>\n",
       "      <td>0</td>\n",
       "      <td>436680</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>15</td>\n",
       "      <td>438</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>605</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>28082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>25545</td>\n",
       "      <td>0</td>\n",
       "      <td>1521</td>\n",
       "      <td>0</td>\n",
       "      <td>853118</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>446</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>870</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>13522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>29</td>\n",
       "      <td>13600</td>\n",
       "      <td>0</td>\n",
       "      <td>288</td>\n",
       "      <td>0</td>\n",
       "      <td>603400</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>132</td>\n",
       "      <td>62</td>\n",
       "      <td>5</td>\n",
       "      <td>802</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "      <td>72968</td>\n",
       "      <td>0</td>\n",
       "      <td>3183</td>\n",
       "      <td>0</td>\n",
       "      <td>258134</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>1213</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>9756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>52376</td>\n",
       "      <td>0</td>\n",
       "      <td>692</td>\n",
       "      <td>0</td>\n",
       "      <td>776626</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>57</td>\n",
       "      <td>787</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>986</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>12781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>37</td>\n",
       "      <td>39704</td>\n",
       "      <td>1</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>634939</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>20</td>\n",
       "      <td>799</td>\n",
       "      <td>54</td>\n",
       "      <td>2</td>\n",
       "      <td>1308</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>16621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>61580</td>\n",
       "      <td>0</td>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>337977</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>338</td>\n",
       "      <td>25</td>\n",
       "      <td>515</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>722</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>20863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>9</td>\n",
       "      <td>42687</td>\n",
       "      <td>0</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>687440</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>45</td>\n",
       "      <td>2202</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>1557</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>14636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>43256</td>\n",
       "      <td>0</td>\n",
       "      <td>2190</td>\n",
       "      <td>0</td>\n",
       "      <td>474013</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>957</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>1098</td>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>7847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>73</td>\n",
       "      <td>29090</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>1</td>\n",
       "      <td>386497</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>49</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>1130</td>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "      <td>9597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>40697</td>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>454622</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>1106</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>1160</td>\n",
       "      <td>0</td>\n",
       "      <td>112</td>\n",
       "      <td>10528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>23</td>\n",
       "      <td>27450</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>779342</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>597</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>1341</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>57238</td>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "      <td>0</td>\n",
       "      <td>448893</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>49</td>\n",
       "      <td>830</td>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>1137</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>14856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>36</td>\n",
       "      <td>34636</td>\n",
       "      <td>0</td>\n",
       "      <td>1496</td>\n",
       "      <td>0</td>\n",
       "      <td>568303</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "      <td>11</td>\n",
       "      <td>639</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>13680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Outcomes ITGB2 ABCG2   MMP2 IFNG CXCL12 HPGDS      FN1 CYP2B6 ADH1A  ...  \\\n",
       "1         1    15     8  31897    0   1255     0  1027006      1     4  ...   \n",
       "2         1    20   133  26183    0    111     0   467407      1     0  ...   \n",
       "3         0    19    15  58028    0    895     0   573809      0     1  ...   \n",
       "4         0    10    51  38045    0     20     0   236591      0     0  ...   \n",
       "5         0     6    26  48239    0   1550     0   435965      0     0  ...   \n",
       "6         0    17    11  24710    0    293     3  1600799      0     4  ...   \n",
       "7         1     6    16  22032    0    137     0   564610      0     0  ...   \n",
       "8         1    42    13  20913    0    993     0   881463      1     0  ...   \n",
       "9         0    11    16  22709    0     12     0   808555      0     4  ...   \n",
       "10        0     7    14  19557    0    235     0  1319261      0     2  ...   \n",
       "11        1     4     4  14580    0    503     0   887571      0    11  ...   \n",
       "12        1     8    21   8372    0     56     0   427432      1     0  ...   \n",
       "13        0     6    24  20140    0    177     0  1125199      1     0  ...   \n",
       "14        0    22    20  44296    0   1685     0   614962      0     2  ...   \n",
       "15        0    17    23  32153    0   1030     0   601137      1     1  ...   \n",
       "16        0    15    19  68807    0   5705     1   895780      0     4  ...   \n",
       "17        1    13    42  44515    0    901     0   193947      0     1  ...   \n",
       "18        0     7    23  21588    0   1441     0  1167185      0     1  ...   \n",
       "19        0     5    18  56925    0   2570     0   530117      1     2  ...   \n",
       "20        0     9    16  52952    0    658     0   549530      0     8  ...   \n",
       "21        1    23    39  55173    0   1162     0   188531      0     0  ...   \n",
       "22        1    16    33  53755    0   1608     0   379301      0     2  ...   \n",
       "23        0    14    24  47742    0    957     0   432017      0     2  ...   \n",
       "24        1    17     9  41991    0    284     0   538509      1     4  ...   \n",
       "25        0    16    23  55573    0    127     0   250661      1    10  ...   \n",
       "26        0   384   215  17995   32    431    40   400690    224   135  ...   \n",
       "27        1    16    58  70283    0   2204     0   436680      0     2  ...   \n",
       "28        1    18     3  25545    0   1521     0   853118      2     1  ...   \n",
       "29        1     8    29  13600    0    288     0   603400      0     0  ...   \n",
       "30        0     8    19  72968    0   3183     0   258134      0     5  ...   \n",
       "31        1     7    13  52376    0    692     0   776626      0     1  ...   \n",
       "32        1     8    37  39704    1    724     0   634939      0     1  ...   \n",
       "33        0     3    29  61580    0    430     0   337977      1     0  ...   \n",
       "34        1    28     9  42687    0    197     0   687440      0     1  ...   \n",
       "35        0    10    10  43256    0   2190     0   474013      0     5  ...   \n",
       "36        1    15    73  29090    0    457     1   386497      0     3  ...   \n",
       "37        1     3    12  40697    0    869     0   454622      0     2  ...   \n",
       "38        1    14    23  27450    0    283     0   779342      2     1  ...   \n",
       "39        1     3    11  57238    0   1038     0   448893      0     6  ...   \n",
       "40        1     8    36  34636    0   1496     0   568303      1     0  ...   \n",
       "\n",
       "   CXCL10 HSD17B2  IL1B   IL6 SLC51A MMP9 PPARG FCGR3A NR1H4   CD44  \n",
       "1       4      11     1   564     42    1  1201      4    15  15904  \n",
       "2       0    1008     7   226    137    1  1069      0   181  23428  \n",
       "3       1      24    20   753     75    4   837      1    64  10936  \n",
       "4       1     267  2079  7136     90    0   926      0    18  12021  \n",
       "5       1      95    12   298     51    1   998      0    12  16665  \n",
       "6       0       4     1   140     54    1  1119      1     1  15996  \n",
       "7       1       3     2    51     41    1   905      0     2  16107  \n",
       "8       0       1     2   392     47    2   815      0    13   9006  \n",
       "9       2       0     5   473     82    2  2026      0     6   9103  \n",
       "10      2       6    46  1104     59    1  1106      0    11  15177  \n",
       "11      0       0     0   198     43    0   952      0     8   6778  \n",
       "12      0      43    15   360     35    4  1605      0     0  20349  \n",
       "13      0      12     3   173     70    1   854      0     3  16721  \n",
       "14      0      50    16   545     36    0   875      0     1  14025  \n",
       "15      1      49    11   990     45    1   726      0     2  12073  \n",
       "16      0       0     1   367     50    0   755      0     5  11475  \n",
       "17      6     724   334  1196     19    2   483      0     4  19673  \n",
       "18      0      58     2   458     62    1  1410      1     5  34084  \n",
       "19      0       4     6   573     38    4   750      0     4  11263  \n",
       "20      2       4     2   903     66    4  1058      0     7  13355  \n",
       "21      8     860   427  1459     45    0   483      0     2  22633  \n",
       "22     11      68    65   257     22    0   818      0     4  14613  \n",
       "23      3      27    13   995     62    2   761      0     9  18256  \n",
       "24      0       4     0   322     77    1   946      2     8   7985  \n",
       "25      0      14     6   773     53    3   934      1     4  15245  \n",
       "26     52      96    69   189    215  239   477    196   128  17585  \n",
       "27      0      40    15   438     68    1   605      0     4  28082  \n",
       "28      1       2     4   446     42    3   870      0    65  13522  \n",
       "29      0       2     4   132     62    5   802      0     0  18188  \n",
       "30      1       9     2    34     42    1  1213      0   109   9756  \n",
       "31      1      63    57   787     29    1   986      0    10  12781  \n",
       "32      0      33    20   799     54    2  1308      0     2  16621  \n",
       "33      0     338    25   515     48    3   722      0    48  20863  \n",
       "34      0     100    45  2202     59    2  1557      0     2  14636  \n",
       "35      0       1     0   957     96    1  1098      0    63   7847  \n",
       "36      9      19     3    49     30    2  1130      0    64   9597  \n",
       "37      0      38    33  1106     36    1  1160      0   112  10528  \n",
       "38      3       1     4   597     60    3  1341      0     1  13270  \n",
       "39      3      52    49   830     61    4  1137      0    15  14856  \n",
       "40      0      13     6    50     29   11   639      0    16  13680  \n",
       "\n",
       "[40 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_online=pd.read_excel('Crohns_Dataset.xlsx',header=None,index_col=False)\n",
    "\n",
    "data_online.columns=data_online.iloc[0].values\n",
    "data_online=data_online.tail(-1)\n",
    "data_online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data_online.iloc[:,1:]\n",
    "\n",
    "Y=data_online.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=Y.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20783,) (28,)\n"
     ]
    }
   ],
   "source": [
    "col_1=data_merged_2.columns.values\n",
    "col_2=X.columns.values\n",
    "\n",
    "print(col_1.shape,col_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_similar=[]\n",
    "for a in col_1:\n",
    "    for b in col_2:\n",
    "        if a==b:\n",
    "            col_similar.append(a)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(col_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.25,random_state=4,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>truncatedsvd0</th>\n",
       "      <th>truncatedsvd1</th>\n",
       "      <th>truncatedsvd2</th>\n",
       "      <th>truncatedsvd3</th>\n",
       "      <th>truncatedsvd4</th>\n",
       "      <th>truncatedsvd5</th>\n",
       "      <th>truncatedsvd6</th>\n",
       "      <th>truncatedsvd7</th>\n",
       "      <th>truncatedsvd8</th>\n",
       "      <th>truncatedsvd9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.329568</td>\n",
       "      <td>0.181943</td>\n",
       "      <td>-0.831977</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.714855</td>\n",
       "      <td>0.052215</td>\n",
       "      <td>0.748916</td>\n",
       "      <td>-0.345790</td>\n",
       "      <td>0.139134</td>\n",
       "      <td>-0.272764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.865697</td>\n",
       "      <td>-0.826349</td>\n",
       "      <td>0.071736</td>\n",
       "      <td>-2.341442</td>\n",
       "      <td>0.950632</td>\n",
       "      <td>1.223115</td>\n",
       "      <td>-1.123787</td>\n",
       "      <td>1.201827</td>\n",
       "      <td>-0.205996</td>\n",
       "      <td>0.833438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.985623</td>\n",
       "      <td>-1.373326</td>\n",
       "      <td>1.530854</td>\n",
       "      <td>-0.399614</td>\n",
       "      <td>2.220887</td>\n",
       "      <td>0.042730</td>\n",
       "      <td>0.034604</td>\n",
       "      <td>1.092365</td>\n",
       "      <td>-1.284721</td>\n",
       "      <td>0.216303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.612533</td>\n",
       "      <td>-0.645965</td>\n",
       "      <td>2.327893</td>\n",
       "      <td>-3.338289</td>\n",
       "      <td>-0.946522</td>\n",
       "      <td>-2.351234</td>\n",
       "      <td>-0.338005</td>\n",
       "      <td>1.566196</td>\n",
       "      <td>1.330114</td>\n",
       "      <td>-0.142624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.875119</td>\n",
       "      <td>-2.588183</td>\n",
       "      <td>0.635601</td>\n",
       "      <td>-1.559754</td>\n",
       "      <td>0.342924</td>\n",
       "      <td>-0.234466</td>\n",
       "      <td>2.068431</td>\n",
       "      <td>-0.298305</td>\n",
       "      <td>0.526291</td>\n",
       "      <td>0.326944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.407945</td>\n",
       "      <td>-1.440853</td>\n",
       "      <td>0.353254</td>\n",
       "      <td>-1.668473</td>\n",
       "      <td>-1.037219</td>\n",
       "      <td>1.441350</td>\n",
       "      <td>-0.286116</td>\n",
       "      <td>-0.225686</td>\n",
       "      <td>0.151958</td>\n",
       "      <td>-0.704211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.472932</td>\n",
       "      <td>0.915925</td>\n",
       "      <td>0.103519</td>\n",
       "      <td>1.891279</td>\n",
       "      <td>0.324923</td>\n",
       "      <td>0.310310</td>\n",
       "      <td>-0.054383</td>\n",
       "      <td>-0.949666</td>\n",
       "      <td>1.174744</td>\n",
       "      <td>-0.329295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.070726</td>\n",
       "      <td>0.154374</td>\n",
       "      <td>0.873843</td>\n",
       "      <td>1.232364</td>\n",
       "      <td>-0.206345</td>\n",
       "      <td>2.919797</td>\n",
       "      <td>0.187864</td>\n",
       "      <td>0.800153</td>\n",
       "      <td>0.121894</td>\n",
       "      <td>-1.173353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.810917</td>\n",
       "      <td>-1.002811</td>\n",
       "      <td>0.065894</td>\n",
       "      <td>0.529135</td>\n",
       "      <td>-0.131544</td>\n",
       "      <td>0.518049</td>\n",
       "      <td>0.980708</td>\n",
       "      <td>-0.391225</td>\n",
       "      <td>0.218749</td>\n",
       "      <td>0.045190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.135143</td>\n",
       "      <td>-0.607129</td>\n",
       "      <td>-0.926190</td>\n",
       "      <td>1.110040</td>\n",
       "      <td>-1.028748</td>\n",
       "      <td>-1.072124</td>\n",
       "      <td>-0.278569</td>\n",
       "      <td>-0.313528</td>\n",
       "      <td>-0.528995</td>\n",
       "      <td>-0.576658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.379939</td>\n",
       "      <td>2.154876</td>\n",
       "      <td>-1.491329</td>\n",
       "      <td>-0.871799</td>\n",
       "      <td>4.133690</td>\n",
       "      <td>-1.290681</td>\n",
       "      <td>0.161242</td>\n",
       "      <td>0.336020</td>\n",
       "      <td>-0.107716</td>\n",
       "      <td>-0.296763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.230560</td>\n",
       "      <td>-1.552771</td>\n",
       "      <td>-2.034793</td>\n",
       "      <td>2.115352</td>\n",
       "      <td>-1.993554</td>\n",
       "      <td>-2.178562</td>\n",
       "      <td>1.548898</td>\n",
       "      <td>0.717147</td>\n",
       "      <td>0.029336</td>\n",
       "      <td>0.058997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-0.237443</td>\n",
       "      <td>0.072850</td>\n",
       "      <td>-1.575463</td>\n",
       "      <td>0.145571</td>\n",
       "      <td>-1.284021</td>\n",
       "      <td>1.056173</td>\n",
       "      <td>-0.567281</td>\n",
       "      <td>0.669614</td>\n",
       "      <td>0.454378</td>\n",
       "      <td>-0.449723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.198459</td>\n",
       "      <td>-0.009172</td>\n",
       "      <td>-0.846003</td>\n",
       "      <td>3.589217</td>\n",
       "      <td>-1.142762</td>\n",
       "      <td>0.503022</td>\n",
       "      <td>-0.157627</td>\n",
       "      <td>2.369331</td>\n",
       "      <td>-0.420733</td>\n",
       "      <td>0.665153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.018764</td>\n",
       "      <td>5.359564</td>\n",
       "      <td>5.717782</td>\n",
       "      <td>0.320578</td>\n",
       "      <td>-1.351799</td>\n",
       "      <td>0.083357</td>\n",
       "      <td>0.999792</td>\n",
       "      <td>-0.104462</td>\n",
       "      <td>-0.503405</td>\n",
       "      <td>0.329029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.555895</td>\n",
       "      <td>0.430253</td>\n",
       "      <td>-0.449686</td>\n",
       "      <td>-0.421361</td>\n",
       "      <td>-0.407800</td>\n",
       "      <td>-0.661617</td>\n",
       "      <td>-1.020546</td>\n",
       "      <td>-0.337387</td>\n",
       "      <td>0.173427</td>\n",
       "      <td>-1.023689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.986818</td>\n",
       "      <td>-0.294168</td>\n",
       "      <td>-0.474490</td>\n",
       "      <td>0.965709</td>\n",
       "      <td>-0.350484</td>\n",
       "      <td>0.303425</td>\n",
       "      <td>-0.423262</td>\n",
       "      <td>-0.455993</td>\n",
       "      <td>0.801547</td>\n",
       "      <td>1.177400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.879662</td>\n",
       "      <td>-1.143923</td>\n",
       "      <td>0.225809</td>\n",
       "      <td>-0.328105</td>\n",
       "      <td>1.201137</td>\n",
       "      <td>0.262352</td>\n",
       "      <td>0.170447</td>\n",
       "      <td>0.060140</td>\n",
       "      <td>-0.324009</td>\n",
       "      <td>0.253614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.726590</td>\n",
       "      <td>0.500177</td>\n",
       "      <td>0.327282</td>\n",
       "      <td>1.641120</td>\n",
       "      <td>0.671283</td>\n",
       "      <td>-1.056703</td>\n",
       "      <td>-0.009223</td>\n",
       "      <td>-0.098168</td>\n",
       "      <td>-1.032301</td>\n",
       "      <td>-0.735821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.758243</td>\n",
       "      <td>-1.359876</td>\n",
       "      <td>-0.155756</td>\n",
       "      <td>-0.141780</td>\n",
       "      <td>-1.529161</td>\n",
       "      <td>-0.343528</td>\n",
       "      <td>-0.757199</td>\n",
       "      <td>-1.005566</td>\n",
       "      <td>-0.706926</td>\n",
       "      <td>0.495938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.967905</td>\n",
       "      <td>1.467825</td>\n",
       "      <td>0.873368</td>\n",
       "      <td>1.965286</td>\n",
       "      <td>1.284799</td>\n",
       "      <td>-0.074286</td>\n",
       "      <td>-0.454685</td>\n",
       "      <td>-0.718962</td>\n",
       "      <td>0.149991</td>\n",
       "      <td>0.107477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.094693</td>\n",
       "      <td>5.501525</td>\n",
       "      <td>-4.536714</td>\n",
       "      <td>-3.446737</td>\n",
       "      <td>-1.177998</td>\n",
       "      <td>0.742654</td>\n",
       "      <td>0.944544</td>\n",
       "      <td>0.083707</td>\n",
       "      <td>-0.492673</td>\n",
       "      <td>0.199080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-0.754261</td>\n",
       "      <td>-1.667127</td>\n",
       "      <td>0.264541</td>\n",
       "      <td>-1.334875</td>\n",
       "      <td>-0.816927</td>\n",
       "      <td>0.663771</td>\n",
       "      <td>-0.956212</td>\n",
       "      <td>-0.501239</td>\n",
       "      <td>-0.525662</td>\n",
       "      <td>0.167385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.756114</td>\n",
       "      <td>1.210002</td>\n",
       "      <td>0.274695</td>\n",
       "      <td>-0.268303</td>\n",
       "      <td>-1.436177</td>\n",
       "      <td>-0.952227</td>\n",
       "      <td>-1.327537</td>\n",
       "      <td>-0.878825</td>\n",
       "      <td>-0.392337</td>\n",
       "      <td>0.549713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.965953</td>\n",
       "      <td>-2.075431</td>\n",
       "      <td>-0.259867</td>\n",
       "      <td>0.099582</td>\n",
       "      <td>0.760317</td>\n",
       "      <td>1.104888</td>\n",
       "      <td>0.869407</td>\n",
       "      <td>-1.086499</td>\n",
       "      <td>-0.655495</td>\n",
       "      <td>0.632542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.860235</td>\n",
       "      <td>0.069245</td>\n",
       "      <td>0.445606</td>\n",
       "      <td>0.167693</td>\n",
       "      <td>0.759588</td>\n",
       "      <td>0.311829</td>\n",
       "      <td>-0.140987</td>\n",
       "      <td>0.221438</td>\n",
       "      <td>0.974071</td>\n",
       "      <td>-0.366963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.731290</td>\n",
       "      <td>1.322748</td>\n",
       "      <td>-0.685276</td>\n",
       "      <td>1.282090</td>\n",
       "      <td>1.200522</td>\n",
       "      <td>0.057874</td>\n",
       "      <td>-0.616540</td>\n",
       "      <td>-0.349956</td>\n",
       "      <td>1.635370</td>\n",
       "      <td>0.751327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.810121</td>\n",
       "      <td>-0.223750</td>\n",
       "      <td>-0.177405</td>\n",
       "      <td>0.177220</td>\n",
       "      <td>0.461351</td>\n",
       "      <td>-1.217207</td>\n",
       "      <td>-0.885498</td>\n",
       "      <td>-0.329945</td>\n",
       "      <td>-0.760994</td>\n",
       "      <td>-0.393067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>19.880413</td>\n",
       "      <td>-0.649580</td>\n",
       "      <td>-0.451263</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.392160</td>\n",
       "      <td>-0.280061</td>\n",
       "      <td>-0.030195</td>\n",
       "      <td>-0.087307</td>\n",
       "      <td>0.008186</td>\n",
       "      <td>0.038826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.580245</td>\n",
       "      <td>-1.880892</td>\n",
       "      <td>0.804536</td>\n",
       "      <td>-1.792210</td>\n",
       "      <td>-0.578008</td>\n",
       "      <td>0.115785</td>\n",
       "      <td>0.712802</td>\n",
       "      <td>-0.639430</td>\n",
       "      <td>0.052774</td>\n",
       "      <td>-0.383426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.883732</td>\n",
       "      <td>-0.705919</td>\n",
       "      <td>0.539093</td>\n",
       "      <td>-0.064723</td>\n",
       "      <td>1.199356</td>\n",
       "      <td>-0.688749</td>\n",
       "      <td>-0.499578</td>\n",
       "      <td>0.266617</td>\n",
       "      <td>-0.980662</td>\n",
       "      <td>-0.137477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.872904</td>\n",
       "      <td>-0.634990</td>\n",
       "      <td>0.433693</td>\n",
       "      <td>-0.029132</td>\n",
       "      <td>1.090793</td>\n",
       "      <td>-0.766487</td>\n",
       "      <td>-0.556348</td>\n",
       "      <td>0.178860</td>\n",
       "      <td>-0.948348</td>\n",
       "      <td>-0.175076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    truncatedsvd0  truncatedsvd1  truncatedsvd2  truncatedsvd3  truncatedsvd4  \\\n",
       "0       -1.329568       0.181943      -0.831977       0.639344       0.714855   \n",
       "1       -0.865697      -0.826349       0.071736      -2.341442       0.950632   \n",
       "2       -0.985623      -1.373326       1.530854      -0.399614       2.220887   \n",
       "3       -0.612533      -0.645965       2.327893      -3.338289      -0.946522   \n",
       "4       -0.875119      -2.588183       0.635601      -1.559754       0.342924   \n",
       "5       -0.407945      -1.440853       0.353254      -1.668473      -1.037219   \n",
       "6       -0.472932       0.915925       0.103519       1.891279       0.324923   \n",
       "7        0.070726       0.154374       0.873843       1.232364      -0.206345   \n",
       "8       -0.810917      -1.002811       0.065894       0.529135      -0.131544   \n",
       "9       -1.135143      -0.607129      -0.926190       1.110040      -1.028748   \n",
       "10      -1.379939       2.154876      -1.491329      -0.871799       4.133690   \n",
       "11      -1.230560      -1.552771      -2.034793       2.115352      -1.993554   \n",
       "12      -0.237443       0.072850      -1.575463       0.145571      -1.284021   \n",
       "13      -0.198459      -0.009172      -0.846003       3.589217      -1.142762   \n",
       "14       1.018764       5.359564       5.717782       0.320578      -1.351799   \n",
       "15      -0.555895       0.430253      -0.449686      -0.421361      -0.407800   \n",
       "16      -0.986818      -0.294168      -0.474490       0.965709      -0.350484   \n",
       "17      -0.879662      -1.143923       0.225809      -0.328105       1.201137   \n",
       "18      -0.726590       0.500177       0.327282       1.641120       0.671283   \n",
       "19      -0.758243      -1.359876      -0.155756      -0.141780      -1.529161   \n",
       "20      -0.967905       1.467825       0.873368       1.965286       1.284799   \n",
       "21      -0.094693       5.501525      -4.536714      -3.446737      -1.177998   \n",
       "22      -0.754261      -1.667127       0.264541      -1.334875      -0.816927   \n",
       "23      -0.756114       1.210002       0.274695      -0.268303      -1.436177   \n",
       "24      -0.965953      -2.075431      -0.259867       0.099582       0.760317   \n",
       "25      -0.860235       0.069245       0.445606       0.167693       0.759588   \n",
       "26      -0.731290       1.322748      -0.685276       1.282090       1.200522   \n",
       "27      -0.810121      -0.223750      -0.177405       0.177220       0.461351   \n",
       "28      19.880413      -0.649580      -0.451263       0.041164       0.392160   \n",
       "29      -0.580245      -1.880892       0.804536      -1.792210      -0.578008   \n",
       "30      -0.883732      -0.705919       0.539093      -0.064723       1.199356   \n",
       "31      -0.872904      -0.634990       0.433693      -0.029132       1.090793   \n",
       "\n",
       "    truncatedsvd5  truncatedsvd6  truncatedsvd7  truncatedsvd8  truncatedsvd9  \n",
       "0        0.052215       0.748916      -0.345790       0.139134      -0.272764  \n",
       "1        1.223115      -1.123787       1.201827      -0.205996       0.833438  \n",
       "2        0.042730       0.034604       1.092365      -1.284721       0.216303  \n",
       "3       -2.351234      -0.338005       1.566196       1.330114      -0.142624  \n",
       "4       -0.234466       2.068431      -0.298305       0.526291       0.326944  \n",
       "5        1.441350      -0.286116      -0.225686       0.151958      -0.704211  \n",
       "6        0.310310      -0.054383      -0.949666       1.174744      -0.329295  \n",
       "7        2.919797       0.187864       0.800153       0.121894      -1.173353  \n",
       "8        0.518049       0.980708      -0.391225       0.218749       0.045190  \n",
       "9       -1.072124      -0.278569      -0.313528      -0.528995      -0.576658  \n",
       "10      -1.290681       0.161242       0.336020      -0.107716      -0.296763  \n",
       "11      -2.178562       1.548898       0.717147       0.029336       0.058997  \n",
       "12       1.056173      -0.567281       0.669614       0.454378      -0.449723  \n",
       "13       0.503022      -0.157627       2.369331      -0.420733       0.665153  \n",
       "14       0.083357       0.999792      -0.104462      -0.503405       0.329029  \n",
       "15      -0.661617      -1.020546      -0.337387       0.173427      -1.023689  \n",
       "16       0.303425      -0.423262      -0.455993       0.801547       1.177400  \n",
       "17       0.262352       0.170447       0.060140      -0.324009       0.253614  \n",
       "18      -1.056703      -0.009223      -0.098168      -1.032301      -0.735821  \n",
       "19      -0.343528      -0.757199      -1.005566      -0.706926       0.495938  \n",
       "20      -0.074286      -0.454685      -0.718962       0.149991       0.107477  \n",
       "21       0.742654       0.944544       0.083707      -0.492673       0.199080  \n",
       "22       0.663771      -0.956212      -0.501239      -0.525662       0.167385  \n",
       "23      -0.952227      -1.327537      -0.878825      -0.392337       0.549713  \n",
       "24       1.104888       0.869407      -1.086499      -0.655495       0.632542  \n",
       "25       0.311829      -0.140987       0.221438       0.974071      -0.366963  \n",
       "26       0.057874      -0.616540      -0.349956       1.635370       0.751327  \n",
       "27      -1.217207      -0.885498      -0.329945      -0.760994      -0.393067  \n",
       "28      -0.280061      -0.030195      -0.087307       0.008186       0.038826  \n",
       "29       0.115785       0.712802      -0.639430       0.052774      -0.383426  \n",
       "30      -0.688749      -0.499578       0.266617      -0.980662      -0.137477  \n",
       "31      -0.766487      -0.556348       0.178860      -0.948348      -0.175076  "
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_train=Pipeline([\n",
    "    # (\"Minmax\",MinMaxScaler()),\n",
    "    # (\"Yeo-johnson\",PowerTransformer(method='yeo-johnson',standardize=True)),\n",
    "    # (\"Binss\",KBinsDiscretizer(n_bins=50,encode='ordinal',strategy='quantile',dtype=np.float32,subsample='warn',random_state=55)),\n",
    "    # (\"NMF\",NMF(n_components=15,random_state=44)),\n",
    "    # (\"Robust Scaler\",RobustScaler()),\n",
    "    (\"Scaler\",StandardScaler()),\n",
    "    # (\"Quantile\",QuantileTransformer(n_quantiles=117,output_distribution='normal',random_state=77)),\n",
    "    # `(\"SVD\",TruncatedSVD(n_components=20,random_state=89))` is adding a step to the pipeline. It is applying the TruncatedSVD (Singular Value Decomposition) dimensionality reduction technique to the data.\n",
    "    (\"SVD\",TruncatedSVD(n_components=10,random_state=890))\n",
    "    # (\"Robust Scaler\",RobustScaler())\n",
    "    # (\"Yeo-johnson\",PowerTransformer(method='yeo-johnson',standardize=False)),\n",
    "    # (\"Quantile\",QuantileTransformer(n_quantiles=1000,output_distribution='normal',random_state=77))\n",
    "    # (\"Binss\",KBinsDiscretizer(n_bins=100,encode='ordinal',strategy='quantile',dtype=np.float32,subsample='warn',random_state=55)),\n",
    "    # (\"NMF\",NMF(n_components=10,random_state=0)),\n",
    "    # (\"Yeo-johnson\",PowerTransformer(method='yeo-johnson',standardize=True))  \n",
    "]).set_output(transform=\"pandas\")\n",
    "\n",
    "X_train_piped=pipe_train.fit_transform(X_train)\n",
    "\n",
    "\n",
    "smote=SMOTE(k_neighbors=2,random_state=227)\n",
    "X_smote,Y_smote=smote.fit_resample(X_train_piped,Y_train)\n",
    "\n",
    "X_smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network : 0.7095238095238094\n",
      "LogisticRegression : 0.6571428571428571\n",
      "ExtraTreesClassifier : 0.6238095238095237\n",
      "DecisionTree : 0.5380952380952381\n",
      "RandomForest : 0.5619047619047619\n",
      "Naive Bayes : 0.5619047619047619\n",
      "KNeighbours : 0.7190476190476189\n",
      "SVM : 0.6523809523809524\n",
      "AdaBoostClassifier : 0.5333333333333333\n",
      "GradientBoostingClassifier:  0.5619047619047619\n",
      "XGB : 0.5666666666666667\n",
      "ExtraTree 0.5904761904761904\n",
      "CatBoost : 0.5619047619047619\n"
     ]
    }
   ],
   "source": [
    "classifiers = [['Neural Network :', MLPClassifier(max_iter = 1000)],\n",
    "               ['LogisticRegression :', LogisticRegression(max_iter = 1000)],\n",
    "               ['ExtraTreesClassifier :', ExtraTreesClassifier()],\n",
    "               ['DecisionTree :',DecisionTreeClassifier()],\n",
    "               ['RandomForest :',RandomForestClassifier(n_estimators=300)], \n",
    "               ['Naive Bayes :', GaussianNB()],\n",
    "               ['KNeighbours :', KNeighborsClassifier()],\n",
    "               ['SVM :', SVC()],\n",
    "               ['AdaBoostClassifier :', AdaBoostClassifier()],\n",
    "               ['GradientBoostingClassifier: ', GradientBoostingClassifier()],\n",
    "               ['XGB :', XGBClassifier()],\n",
    "               ['ExtraTree',ExtraTreesClassifier(n_estimators=500)],\n",
    "               ['CatBoost :', CatBoostClassifier(logging_level='Silent')]]\n",
    "\n",
    "\n",
    "for name,classifier in classifiers:\n",
    "    scores = cross_val_score(classifier, X_smote, Y_smote, cv=5, scoring='accuracy')\n",
    "    print(name, scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6857142857142857\n"
     ]
    }
   ],
   "source": [
    "vot=VotingClassifier([\n",
    "    ('XGB',ExtraTreesClassifier(n_estimators=500)),('Cat',CatBoostClassifier(logging_level='Silent')),('GB',GradientBoostingClassifier())\n",
    "],voting='soft')\n",
    "scores = cross_val_score(vot, X_smote, Y_smote, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'alpha': 0.01, 'hidden_layer_sizes': (10, 30, 10), 'learning_rate': 'constant', 'solver': 'adam'}\n",
      "[1.         0.71428571 0.66666667 0.83333333 0.66666667]\n",
      "0.7761904761904762 0.1274198872405681\n"
     ]
    }
   ],
   "source": [
    "#MLP Optimization\n",
    "\n",
    "mlp_gs = MLPClassifier(max_iter=20000)\n",
    "parameter_space = {\n",
    "    'hidden_layer_sizes': [(10,30,10),(500,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam'],\n",
    "    'alpha': [0.05,0.01,0.1,0.5],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "\n",
    "clf_mlp = GridSearchCV(mlp_gs, parameter_space, n_jobs=-1, cv=5)\n",
    "clf_mlp.fit(X_smote, Y_smote)\n",
    "\n",
    "mlp_opt=clf_mlp.best_estimator_\n",
    "\n",
    "print(clf_mlp.best_params_)\n",
    "\n",
    "scores = cross_val_score(mlp_opt, X_smote, Y_smote, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean(),scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 4, 'min_samples_leaf': 2, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "# Optimization\n",
    "DTree=DecisionTreeClassifier()\n",
    "params={'criterion':['gini', 'entropy'],\n",
    "    'max_depth':[1,2,4,6,8,10,12],\n",
    "    'min_samples_split':range(1,11),\n",
    "    'min_samples_leaf':range(1,11)}\n",
    "\n",
    "grid_dtree_s=GridSearchCV(DTree,params)\n",
    "\n",
    "grid_dtree_s.fit(X_smote,Y_smote)\n",
    "\n",
    "tree_opt_s=grid_dtree_s.best_estimator_\n",
    "\n",
    "\n",
    "print(grid_dtree_s.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71428571 0.42857143 0.66666667 0.5        0.66666667]\n",
      "0.5952380952380951 0.11065666703449763\n"
     ]
    }
   ],
   "source": [
    "dt=clone(tree_opt)\n",
    "scores_dt = cross_val_score(dt, X_smote, Y_smote, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores_dt)\n",
    "print(scores_dt.mean(),scores_dt.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71428571 0.71428571 0.83333333 0.5        0.83333333]\n",
      "0.719047619047619 0.1217782081194707\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(dt, n_estimators=100, random_state=0,oob_score=True)\n",
    "\n",
    "scores = cross_val_score(clf, X_smote, Y_smote, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores)\n",
    "print(scores.mean(),scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4 0.42857142857142855 0.6 0.5\n"
     ]
    }
   ],
   "source": [
    "clone_dt=clone(mlp_opt)\n",
    "clone_dt.fit(X_smote,Y_smote)\n",
    "\n",
    "y_predict=clone_dt.predict(X_test_piped)\n",
    "acc=accuracy_score(Y_test,y_predict)\n",
    "pr=precision_score(Y_test,y_predict)\n",
    "recall=recall_score(Y_test,y_predict)\n",
    "f1=f1_score(Y_test,y_predict)\n",
    "print(acc,pr,recall,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 9, 'min_samples_leaf': 3, 'min_samples_split': 3, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "#optimizaing random forest\n",
    "grid_space={'max_depth':[10,50,100,None],\n",
    "              'n_estimators':[200,300,700],\n",
    "              'max_features':[7,9,13],\n",
    "              'min_samples_leaf':[1,2,3],\n",
    "              'min_samples_split':[1,2,3]\n",
    "           }\n",
    "grid_RF = GridSearchCV(RandomForestClassifier(), grid_space, refit = True) \n",
    "\n",
    "# fitting the model for grid search \n",
    "grid_RF.fit(X_train_piped, Y_train) \n",
    "\n",
    "print(grid_RF.best_params_)\n",
    "rfff=grid_RF.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.5        0.66666667 0.66666667 0.33333333]\n",
      "0.5666666666666667 0.13333333333333333\n"
     ]
    }
   ],
   "source": [
    "rf=clone(rfff)\n",
    "scores_rf = cross_val_score(rf, X_train_piped, Y_train, cv=5, scoring='accuracy')\n",
    "\n",
    "print(scores_rf)\n",
    "print(scores_rf.mean(),scores_rf.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.01, 'max_depth': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# XGBOOST\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb=XGBClassifier()\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (2, 20, 1),\n",
    "    'n_estimators': range(60, 500, 40),\n",
    "    'learning_rate': [0.1, 0.01, 0.05]\n",
    "}\n",
    "xgb_grid=GridSearchCV(xgb,param_grid=parameters,cv=5,n_jobs=-1)\n",
    "\n",
    "xgb_grid.fit(X_smote,Y_smote)\n",
    "\n",
    "xgb_best=xgb_grid.best_estimator_\n",
    "\n",
    "print(xgb_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5380952380952382\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = cross_val_score(xgb_best,X_smote,Y_smote, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 4, 'iterations': 10, 'learning_rate': 0.02, 'logging_level': 'Silent'}\n"
     ]
    }
   ],
   "source": [
    "CAT=CatBoostClassifier()\n",
    "parameters = {'depth'         : [4,5,6,7,8,9, 10],\n",
    "                 'learning_rate' : [0.01,0.02,0.03,0.04],\n",
    "                  'iterations'    : [10, 20,30,40,50,60,70,80,90, 100],\n",
    "                  'logging_level':['Silent']\n",
    "                 }\n",
    "CAT_grid=GridSearchCV(CAT,param_grid=parameters,cv=5,n_jobs=-1)\n",
    "\n",
    "CAT_grid.fit(X_smote,Y_smote)\n",
    "\n",
    "CAT_best=CAT_grid.best_estimator_\n",
    "\n",
    "print(CAT_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.557142857142857\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(CAT_best, X_smote,Y_smote, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_piped=pipe_train.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 1.0 0.2 0.33333333333333337\n"
     ]
    }
   ],
   "source": [
    "clone_CAT=clone(CAT_best)\n",
    "clone_CAT.fit(X_smote,Y_smote)\n",
    "\n",
    "y_predict=clone_CAT.predict(X_test_piped)\n",
    "acc=accuracy_score(Y_test,y_predict)\n",
    "pr=precision_score(Y_test,y_predict)\n",
    "recall=recall_score(Y_test,y_predict)\n",
    "f1=f1_score(Y_test,y_predict)\n",
    "print(acc,pr,recall,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6 0.6666666666666666 0.4 0.5\n"
     ]
    }
   ],
   "source": [
    "clone_CAT=clone(xgb_best)\n",
    "clone_CAT.fit(X_smote,Y_smote)\n",
    "\n",
    "y_predict=clone_CAT.predict(X_test_piped)\n",
    "acc=accuracy_score(Y_test,y_predict)\n",
    "pr=precision_score(Y_test,y_predict)\n",
    "recall=recall_score(Y_test,y_predict)\n",
    "f1=f1_score(Y_test,y_predict)\n",
    "print(acc,pr,recall,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 17, 'n_estimators': 380}\n"
     ]
    }
   ],
   "source": [
    "exT=ExtraTreesClassifier()\n",
    "parameters = {\n",
    "    'max_depth': range (2, 20, 1),\n",
    "    'n_estimators': range(60, 500, 40),\n",
    "}\n",
    "exT_grid=GridSearchCV(exT,param_grid=parameters,cv=5,n_jobs=-1)\n",
    "\n",
    "exT_grid.fit(X_smote,Y_smote)\n",
    "\n",
    "exT_best=exT_grid.best_estimator_\n",
    "\n",
    "print(exT_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7904761904761906\n"
     ]
    }
   ],
   "source": [
    "GB=GradientBoostingClassifier()\n",
    "scores = cross_val_score(GB, X_smote,Y_smote, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 80 candidates, totalling 400 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 400 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 162, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 569, in _boost\n    return self._boost_real(iboost, X, y, sample_weight, random_state)\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 578, in _boost_real\n    estimator.fit(X, y, sample_weight=sample_weight)\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n    super().fit(\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n    self._validate_params()\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of DecisionTreeClassifier must be an instance of 'dict', an instance of 'list', a str among {'balanced'} or None. Got 'auto' instead.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17416\\935742625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_piped\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mabc_best\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    872\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    873\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 874\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1387\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1388\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1389\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    849\u001b[0m                     )\n\u001b[0;32m    850\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 851\u001b[1;33m                 \u001b[0m_warn_or_raise_about_fit_failures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    853\u001b[0m                 \u001b[1;31m# For callable self.scoring, the return type is only know after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    365\u001b[0m                 \u001b[1;34mf\"Below are more details about the failures:\\n{fit_errors_summary}\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             )\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fits_failed_message\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    369\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 400 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n400 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 162, in fit\n    sample_weight, estimator_weight, estimator_error = self._boost(\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 569, in _boost\n    return self._boost_real(iboost, X, y, sample_weight, random_state)\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_weight_boosting.py\", line 578, in _boost_real\n    estimator.fit(X, y, sample_weight=sample_weight)\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 889, in fit\n    super().fit(\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 177, in fit\n    self._validate_params()\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_params\n    validate_parameter_constraints(\n  File \"c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 97, in validate_parameter_constraints\n    raise InvalidParameterError(\nsklearn.utils._param_validation.InvalidParameterError: The 'class_weight' parameter of DecisionTreeClassifier must be an instance of 'dict', an instance of 'list', a str among {'balanced'} or None. Got 'auto' instead.\n"
     ]
    }
   ],
   "source": [
    "abc = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(random_state = 11, max_features = \"auto\", class_weight = \"auto\",max_depth = None))\n",
    "\n",
    "parameters = {'base_estimator__max_depth':[i for i in range(2,11,2)],\n",
    "              'base_estimator__min_samples_leaf':[5,10],\n",
    "              'n_estimators':[10,50,250,1000],\n",
    "              'learning_rate':[0.01,0.1]}\n",
    "\n",
    "clf = GridSearchCV(abc, parameters,verbose=3,scoring='accuracy',n_jobs=-1)\n",
    "clf.fit(X_train_piped,Y_train)\n",
    "\n",
    "abc_best=clf.best_estimator_\n",
    "\n",
    "print(clf.best_params_)\n",
    "\n",
    "scores = cross_val_score(abc_best, X_smote,Y_smote, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n",
      "c:\\Users\\irfan\\anaconda3_new\\lib\\site-packages\\sklearn\\ensemble\\_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "voting_Boosts=VotingClassifier(estimators=[\n",
    "    ('xgb',xgb_best),\n",
    "    ('extraTree',abc_best),\n",
    "    ('CAT',CAT_best)\n",
    "],voting='soft')\n",
    "\n",
    "scores = cross_val_score(voting_Boosts, X_train_piped,Y_train, cv=5, scoring='accuracy')\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columnselector&#x27;,\n",
       "                 ColumnSelector(cols=[&#x27;ABCB1&#x27;, &#x27;ABCG2&#x27;, &#x27;ACOX1&#x27;, &#x27;ADH1A&#x27;,\n",
       "                                      &#x27;ADH1C&#x27;, &#x27;CCL2&#x27;, &#x27;CD44&#x27;, &#x27;CD86&#x27;, &#x27;CXCL10&#x27;,\n",
       "                                      &#x27;CXCL12&#x27;, &#x27;CYP2B6&#x27;, &#x27;CYP2S1&#x27;, &#x27;FCGR3A&#x27;,\n",
       "                                      &#x27;FN1&#x27;, &#x27;HPGDS&#x27;, &#x27;HSD17B2&#x27;, &#x27;ICAM1&#x27;,\n",
       "                                      &#x27;IFNG&#x27;, &#x27;IL1B&#x27;, &#x27;IL6&#x27;, &#x27;ITGB2&#x27;, &#x27;MMP2&#x27;,\n",
       "                                      &#x27;MMP9&#x27;, &#x27;NR1H4&#x27;, &#x27;SLC51A&#x27;, &#x27;PPARG&#x27;,\n",
       "                                      &#x27;PTPRC&#x27;, &#x27;UGT1A3&#x27;])),\n",
       "                (&#x27;pipeline&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()),\n",
       "                                 (&#x27;SVD&#x27;,\n",
       "                                  TruncatedSVD(n_components=15,\n",
       "                                               random_state=890))])),\n",
       "                (&#x27;mlpclassifier&#x27;,\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(10, 30, 10),\n",
       "                               learning_rate=&#x27;adaptive&#x27;, max_iter=800))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-90\" type=\"checkbox\" ><label for=\"sk-estimator-id-90\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;columnselector&#x27;,\n",
       "                 ColumnSelector(cols=[&#x27;ABCB1&#x27;, &#x27;ABCG2&#x27;, &#x27;ACOX1&#x27;, &#x27;ADH1A&#x27;,\n",
       "                                      &#x27;ADH1C&#x27;, &#x27;CCL2&#x27;, &#x27;CD44&#x27;, &#x27;CD86&#x27;, &#x27;CXCL10&#x27;,\n",
       "                                      &#x27;CXCL12&#x27;, &#x27;CYP2B6&#x27;, &#x27;CYP2S1&#x27;, &#x27;FCGR3A&#x27;,\n",
       "                                      &#x27;FN1&#x27;, &#x27;HPGDS&#x27;, &#x27;HSD17B2&#x27;, &#x27;ICAM1&#x27;,\n",
       "                                      &#x27;IFNG&#x27;, &#x27;IL1B&#x27;, &#x27;IL6&#x27;, &#x27;ITGB2&#x27;, &#x27;MMP2&#x27;,\n",
       "                                      &#x27;MMP9&#x27;, &#x27;NR1H4&#x27;, &#x27;SLC51A&#x27;, &#x27;PPARG&#x27;,\n",
       "                                      &#x27;PTPRC&#x27;, &#x27;UGT1A3&#x27;])),\n",
       "                (&#x27;pipeline&#x27;,\n",
       "                 Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()),\n",
       "                                 (&#x27;SVD&#x27;,\n",
       "                                  TruncatedSVD(n_components=15,\n",
       "                                               random_state=890))])),\n",
       "                (&#x27;mlpclassifier&#x27;,\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(10, 30, 10),\n",
       "                               learning_rate=&#x27;adaptive&#x27;, max_iter=800))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-91\" type=\"checkbox\" ><label for=\"sk-estimator-id-91\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">ColumnSelector</label><div class=\"sk-toggleable__content\"><pre>ColumnSelector(cols=[&#x27;ABCB1&#x27;, &#x27;ABCG2&#x27;, &#x27;ACOX1&#x27;, &#x27;ADH1A&#x27;, &#x27;ADH1C&#x27;, &#x27;CCL2&#x27;,\n",
       "                     &#x27;CD44&#x27;, &#x27;CD86&#x27;, &#x27;CXCL10&#x27;, &#x27;CXCL12&#x27;, &#x27;CYP2B6&#x27;, &#x27;CYP2S1&#x27;,\n",
       "                     &#x27;FCGR3A&#x27;, &#x27;FN1&#x27;, &#x27;HPGDS&#x27;, &#x27;HSD17B2&#x27;, &#x27;ICAM1&#x27;, &#x27;IFNG&#x27;,\n",
       "                     &#x27;IL1B&#x27;, &#x27;IL6&#x27;, &#x27;ITGB2&#x27;, &#x27;MMP2&#x27;, &#x27;MMP9&#x27;, &#x27;NR1H4&#x27;, &#x27;SLC51A&#x27;,\n",
       "                     &#x27;PPARG&#x27;, &#x27;PTPRC&#x27;, &#x27;UGT1A3&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-92\" type=\"checkbox\" ><label for=\"sk-estimator-id-92\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">pipeline: Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;Scaler&#x27;, StandardScaler()),\n",
       "                (&#x27;SVD&#x27;, TruncatedSVD(n_components=15, random_state=890))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-93\" type=\"checkbox\" ><label for=\"sk-estimator-id-93\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-94\" type=\"checkbox\" ><label for=\"sk-estimator-id-94\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TruncatedSVD</label><div class=\"sk-toggleable__content\"><pre>TruncatedSVD(n_components=15, random_state=890)</pre></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-95\" type=\"checkbox\" ><label for=\"sk-estimator-id-95\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(alpha=0.01, hidden_layer_sizes=(10, 30, 10),\n",
       "              learning_rate=&#x27;adaptive&#x27;, max_iter=800)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columnselector',\n",
       "                 ColumnSelector(cols=['ABCB1', 'ABCG2', 'ACOX1', 'ADH1A',\n",
       "                                      'ADH1C', 'CCL2', 'CD44', 'CD86', 'CXCL10',\n",
       "                                      'CXCL12', 'CYP2B6', 'CYP2S1', 'FCGR3A',\n",
       "                                      'FN1', 'HPGDS', 'HSD17B2', 'ICAM1',\n",
       "                                      'IFNG', 'IL1B', 'IL6', 'ITGB2', 'MMP2',\n",
       "                                      'MMP9', 'NR1H4', 'SLC51A', 'PPARG',\n",
       "                                      'PTPRC', 'UGT1A3'])),\n",
       "                ('pipeline',\n",
       "                 Pipeline(steps=[('Scaler', StandardScaler()),\n",
       "                                 ('SVD',\n",
       "                                  TruncatedSVD(n_components=15,\n",
       "                                               random_state=890))])),\n",
       "                ('mlpclassifier',\n",
       "                 MLPClassifier(alpha=0.01, hidden_layer_sizes=(10, 30, 10),\n",
       "                               learning_rate='adaptive', max_iter=800))])"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlxtend.feature_selection import ColumnSelector\n",
    "col_similar_2=pd.DataFrame(col_similar)\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "pipe = make_pipeline(\n",
    "                     ColumnSelector(cols=col_similar),\n",
    "                     pipe_train,\n",
    "                     mlp_opt)\n",
    "\n",
    "pipe.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('Crohns_MLP_ver1.pkl','wb') as file:\n",
    "    pickle.dump(pipe,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     0\n",
       "15    0\n",
       "27    1\n",
       "1     1\n",
       "8     1\n",
       "10    0\n",
       "25    0\n",
       "24    1\n",
       "17    1\n",
       "14    0\n",
       "Name: Outcomes, dtype: int32"
      ]
     },
     "execution_count": 463,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0])"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.predict(data_merged_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'max_iter': 100}\n",
      "Logistic Regression Accuracy: 0.7\n",
      "[[4 1]\n",
      " [2 3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73         5\n",
      "           1       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.70        10\n",
      "   macro avg       0.71      0.70      0.70        10\n",
      "weighted avg       0.71      0.70      0.70        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'max_iter': [100, 500, 1000]}\n",
    "grid_search = GridSearchCV(LogisticRegression(solver='liblinear'), param_grid, cv=5)\n",
    "grid_search.fit(X_smote, Y_smote)\n",
    "\n",
    "# Best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best estimator from the grid search\n",
    "best_logreg = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = best_logreg.predict(X_test_piped)\n",
    "accuracy = accuracy_score(Y_test, y_pred)\n",
    "\n",
    "print(f\"Best Hyperparameters: {best_params}\")\n",
    "print(f\"Logistic Regression Accuracy: {accuracy}\")\n",
    "print(confusion_matrix(Y_test, y_pred))\n",
    "print(classification_report(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('Crohns_CAT_ver1.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict=loaded_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y_test,y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50035619, 0.49964381],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.48109691, 0.51890309],\n",
       "       [0.48367279, 0.51632721],\n",
       "       [0.49973863, 0.50026137],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.48366485, 0.51633515],\n",
       "       [0.50280292, 0.49719708],\n",
       "       [0.48334529, 0.51665471],\n",
       "       [0.48399237, 0.51600763],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50243068, 0.49756932],\n",
       "       [0.48419124, 0.51580876],\n",
       "       [0.48314644, 0.51685356],\n",
       "       [0.49944465, 0.50055535],\n",
       "       [0.48399318, 0.51600682],\n",
       "       [0.48328611, 0.51671389],\n",
       "       [0.48332978, 0.51667022],\n",
       "       [0.48487808, 0.51512192],\n",
       "       [0.48399318, 0.51600682],\n",
       "       [0.48334584, 0.51665416],\n",
       "       [0.48328896, 0.51671104],\n",
       "       [0.48103835, 0.51896165],\n",
       "       [0.48499026, 0.51500974],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.48149748, 0.51850252],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.49778871, 0.50221129],\n",
       "       [0.49973863, 0.50026137],\n",
       "       [0.49998407, 0.50001593],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.49919921, 0.50080079],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50035619, 0.49964381],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.49973863, 0.50026137],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50010425, 0.49989575],\n",
       "       [0.483466  , 0.516534  ],\n",
       "       [0.50243068, 0.49756932],\n",
       "       [0.49064946, 0.50935054],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.49754328, 0.50245672],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50010425, 0.49989575],\n",
       "       [0.49973863, 0.50026137],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50243068, 0.49756932],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50184182, 0.49815818],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50280292, 0.49719708],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50243068, 0.49756932],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50192652, 0.49807348],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50255355, 0.49744645],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.49746881, 0.50253119],\n",
       "       [0.50002977, 0.49997023],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.48851677, 0.51148323],\n",
       "       [0.50184182, 0.49815818],\n",
       "       [0.49998407, 0.50001593],\n",
       "       [0.48532465, 0.51467535],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.48677676, 0.51322324],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.49998407, 0.50001593],\n",
       "       [0.50022884, 0.49977116],\n",
       "       [0.50054875, 0.49945125],\n",
       "       [0.50237102, 0.49762898],\n",
       "       [0.50054875, 0.49945125],\n",
       "       [0.48565985, 0.51434015],\n",
       "       [0.50179983, 0.49820017],\n",
       "       [0.48717946, 0.51282054],\n",
       "       [0.48367279, 0.51632721],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.49553581, 0.50446419],\n",
       "       [0.50034968, 0.49965032],\n",
       "       [0.50035619, 0.49964381],\n",
       "       [0.48387165, 0.51612835],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.49557771, 0.50442229],\n",
       "       [0.50217196, 0.49782804],\n",
       "       [0.5005384 , 0.4994616 ]])"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(data_merged_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
