{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(signal):\n",
    "    mean = np.mean(signal)\n",
    "    max_val = np.max(signal)\n",
    "    min_val = np.min(signal)\n",
    "    rms = np.sqrt(np.mean(np.square(signal)))\n",
    "    kurtosis = pd.Series(signal).kurtosis()\n",
    "    skewness = pd.Series(signal).skew()\n",
    "    std_dev = np.std(signal)\n",
    "    form_factor = rms / mean\n",
    "    crest_factor = max_val / rms\n",
    "    \n",
    "    return [mean, max_val, min_val, rms, kurtosis, skewness, std_dev, form_factor, crest_factor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mat_files(directory):\n",
    "    feature_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for file_name in os.listdir(directory):\n",
    "        if file_name.endswith('.mat'):\n",
    "            file_path = os.path.join(directory, file_name)\n",
    "            mat_data = scipy.io.loadmat(file_path)\n",
    "            signal = mat_data['signal'].flatten()  # Adjust based on how your data is structured\n",
    "            \n",
    "            features = extract_features(signal)\n",
    "            feature_list.append(features)\n",
    "            \n",
    "            # Append the label based on the folder name\n",
    "            label_list.append(directory.split('\\\\')[-1].lower())\n",
    "    \n",
    "    columns = ['mean', 'max', 'min', 'rms', 'kurtosis', 'skewness', 'std_dev', 'form_factor', 'crest_factor']\n",
    "    return pd.DataFrame(feature_list, columns=columns), label_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction complete.\n"
     ]
    }
   ],
   "source": [
    "directories = {\n",
    "    'inner': r'E:\\Bearings\\Dataset\\Bearing Dataset2\\Inner (1800)',\n",
    "    'outer': r'E:\\Bearings\\Dataset\\Bearing Dataset2\\Outer (1800)',\n",
    "    'roller': r'E:\\Bearings\\Dataset\\Bearing Dataset2\\Roller (1800)',\n",
    "    'normal': r'E:\\Bearings\\Dataset\\Bearing Dataset2\\Normal (1800)'\n",
    "}\n",
    "\n",
    "# Initialize an empty DataFrame for features and an empty list for labels\n",
    "all_features = pd.DataFrame()\n",
    "all_labels = []\n",
    "\n",
    "# Process each directory\n",
    "for condition, directory in directories.items():\n",
    "    features, labels = process_mat_files(directory)\n",
    "    all_features = pd.concat([all_features, features], ignore_index=True)\n",
    "    all_labels += labels\n",
    "\n",
    "# Convert the labels to a DataFrame for easier processing\n",
    "all_labels = pd.DataFrame(all_labels, columns=['label'])\n",
    "\n",
    "print(\"Feature extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 959, Validation set size: 205, Test set size: 206\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode the labels (converting 'inner', 'outer', etc. to numeric labels)\n",
    "le = LabelEncoder()\n",
    "all_labels_encoded = le.fit_transform(all_labels.values.ravel())\n",
    "\n",
    "# Combine the features and labels into one DataFrame\n",
    "data = pd.concat([all_features, pd.Series(all_labels_encoded, name='label')], axis=1)\n",
    "\n",
    "# Split the data into training (70%), validation (15%), and test (15%)\n",
    "X = data.drop('label', axis=1)\n",
    "y = data['label']\n",
    "\n",
    "# First, split into training+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.15, random_state=42, stratify=y)\n",
    "\n",
    "# Then, split the training+validation set into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.176, random_state=42, stratify=y_train_val)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}, Validation set size: {X_val.shape[0]}, Test set size: {X_test.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance ratio: [9.99988786e-01 1.03789970e-05 7.38277997e-07 7.36523697e-08\n",
      " 1.74598097e-08]\n"
     ]
    }
   ],
   "source": [
    "# Apply PCA to reduce to 5 principal components\n",
    "pca = PCA(n_components=5)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_val_pca = pca.transform(X_val)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Check explained variance to see how much information is retained\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(f\"Explained variance ratio: {explained_variance_ratio}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating classifiers on PCA-transformed data:\n",
      "Random Forest - Validation Accuracy: 96.59%\n",
      "Random Forest - Test Accuracy: 98.54%\n",
      "Classification Report (Test Set) for Random Forest:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " inner (1800)       0.98      0.98      0.98        56\n",
      "normal (1800)       1.00      0.98      0.99        52\n",
      " outer (1800)       0.98      1.00      0.99        52\n",
      "roller (1800)       0.98      0.98      0.98        46\n",
      "\n",
      "     accuracy                           0.99       206\n",
      "    macro avg       0.99      0.99      0.99       206\n",
      " weighted avg       0.99      0.99      0.99       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Random Forest:\n",
      "[[55  0  0  1]\n",
      " [ 0 51  1  0]\n",
      " [ 0  0 52  0]\n",
      " [ 1  0  0 45]]\n",
      "\n",
      "\n",
      "SVM - Validation Accuracy: 93.66%\n",
      "SVM - Test Accuracy: 93.20%\n",
      "Classification Report (Test Set) for SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " inner (1800)       0.91      0.86      0.88        56\n",
      "normal (1800)       1.00      0.98      0.99        52\n",
      " outer (1800)       0.86      0.96      0.91        52\n",
      "roller (1800)       0.98      0.93      0.96        46\n",
      "\n",
      "     accuracy                           0.93       206\n",
      "    macro avg       0.94      0.93      0.93       206\n",
      " weighted avg       0.93      0.93      0.93       206\n",
      "\n",
      "Confusion Matrix (Test Set) for SVM:\n",
      "[[48  0  7  1]\n",
      " [ 0 51  1  0]\n",
      " [ 2  0 50  0]\n",
      " [ 3  0  0 43]]\n",
      "\n",
      "\n",
      "KNN - Validation Accuracy: 57.56%\n",
      "KNN - Test Accuracy: 52.43%\n",
      "Classification Report (Test Set) for KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " inner (1800)       0.68      0.70      0.69        56\n",
      "normal (1800)       0.42      0.50      0.46        52\n",
      " outer (1800)       0.41      0.37      0.39        52\n",
      "roller (1800)       0.59      0.52      0.55        46\n",
      "\n",
      "     accuracy                           0.52       206\n",
      "    macro avg       0.53      0.52      0.52       206\n",
      " weighted avg       0.53      0.52      0.52       206\n",
      "\n",
      "Confusion Matrix (Test Set) for KNN:\n",
      "[[39  5  3  9]\n",
      " [ 8 26 16  2]\n",
      " [ 4 23 19  6]\n",
      " [ 6  8  8 24]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Initialize classifiers\n",
    "classifiers = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'SVM': SVC(kernel='linear', random_state=42),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5)\n",
    "}\n",
    "\n",
    "print(\"Evaluating classifiers on PCA-transformed data:\")\n",
    "\n",
    "# Train and evaluate each classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Predict on validation and test sets\n",
    "    y_val_pred = clf.predict(X_val_pca)\n",
    "    y_test_pred = clf.predict(X_test_pca)\n",
    "    \n",
    "    # Print validation and test accuracy\n",
    "    val_accuracy = clf.score(X_val_pca, y_val)\n",
    "    test_accuracy = clf.score(X_test_pca, y_test)\n",
    "    print(f\"{name} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"{name} - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Print classification report and confusion matrix\n",
    "    print(f\"Classification Report (Test Set) for {name}:\")\n",
    "    print(classification_report(y_test, y_test_pred, target_names=le.classes_))\n",
    "    \n",
    "    print(f\"Confusion Matrix (Test Set) for {name}:\")\n",
    "    print(confusion_matrix(y_test, y_test_pred))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = {\n",
    "    'Fine Tree': DecisionTreeClassifier(max_depth=100, criterion='gini'),\n",
    "    'Medium Tree': DecisionTreeClassifier(max_depth=20, criterion='gini'),\n",
    "    'Coarse Tree': DecisionTreeClassifier(max_depth=4, criterion='gini'),\n",
    "    'Linear Discriminant': LinearDiscriminantAnalysis(),\n",
    "    'Quadratic Discriminant': QuadraticDiscriminantAnalysis()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine Tree - Validation Accuracy: 95.12%\n",
      "Fine Tree - Test Accuracy: 96.60%\n",
      "Classification Report (Test Set) for Fine Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        56\n",
      "           1       0.98      0.96      0.97        52\n",
      "           2       0.94      0.96      0.95        52\n",
      "           3       0.96      1.00      0.98        46\n",
      "\n",
      "    accuracy                           0.97       206\n",
      "   macro avg       0.97      0.97      0.97       206\n",
      "weighted avg       0.97      0.97      0.97       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Fine Tree:\n",
      " [[53  0  1  2]\n",
      " [ 0 50  2  0]\n",
      " [ 1  1 50  0]\n",
      " [ 0  0  0 46]]\n",
      "\n",
      "Medium Tree - Validation Accuracy: 94.15%\n",
      "Medium Tree - Test Accuracy: 97.09%\n",
      "Classification Report (Test Set) for Medium Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97        56\n",
      "           1       0.98      0.96      0.97        52\n",
      "           2       0.94      0.96      0.95        52\n",
      "           3       0.98      1.00      0.99        46\n",
      "\n",
      "    accuracy                           0.97       206\n",
      "   macro avg       0.97      0.97      0.97       206\n",
      "weighted avg       0.97      0.97      0.97       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Medium Tree:\n",
      " [[54  0  1  1]\n",
      " [ 0 50  2  0]\n",
      " [ 1  1 50  0]\n",
      " [ 0  0  0 46]]\n",
      "\n",
      "Coarse Tree - Validation Accuracy: 89.27%\n",
      "Coarse Tree - Test Accuracy: 93.20%\n",
      "Classification Report (Test Set) for Coarse Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90        56\n",
      "           1       0.98      0.96      0.97        52\n",
      "           2       0.86      0.94      0.90        52\n",
      "           3       0.92      1.00      0.96        46\n",
      "\n",
      "    accuracy                           0.93       206\n",
      "   macro avg       0.93      0.94      0.93       206\n",
      "weighted avg       0.94      0.93      0.93       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Coarse Tree:\n",
      " [[47  0  6  3]\n",
      " [ 0 50  2  0]\n",
      " [ 1  1 49  1]\n",
      " [ 0  0  0 46]]\n",
      "\n",
      "Linear Discriminant - Validation Accuracy: 93.17%\n",
      "Linear Discriminant - Test Accuracy: 92.72%\n",
      "Classification Report (Test Set) for Linear Discriminant:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        56\n",
      "           1       0.96      0.98      0.97        52\n",
      "           2       0.85      0.96      0.90        52\n",
      "           3       0.92      0.96      0.94        46\n",
      "\n",
      "    accuracy                           0.93       206\n",
      "   macro avg       0.93      0.93      0.93       206\n",
      "weighted avg       0.93      0.93      0.93       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Linear Discriminant:\n",
      " [[46  0  6  4]\n",
      " [ 0 51  1  0]\n",
      " [ 0  2 50  0]\n",
      " [ 0  0  2 44]]\n",
      "\n",
      "Quadratic Discriminant - Validation Accuracy: 95.61%\n",
      "Quadratic Discriminant - Test Accuracy: 97.57%\n",
      "Classification Report (Test Set) for Quadratic Discriminant:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        56\n",
      "           1       1.00      0.98      0.99        52\n",
      "           2       0.98      1.00      0.99        52\n",
      "           3       0.94      0.98      0.96        46\n",
      "\n",
      "    accuracy                           0.98       206\n",
      "   macro avg       0.98      0.98      0.98       206\n",
      "weighted avg       0.98      0.98      0.98       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Quadratic Discriminant:\n",
      " [[53  0  0  3]\n",
      " [ 0 51  1  0]\n",
      " [ 0  0 52  0]\n",
      " [ 1  0  0 45]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Assuming y_train contains the original labels (either categorical or integer)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_val_encoded = label_encoder.transform(y_val)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Convert class indices back to strings (or use actual class names if available)\n",
    "class_names = list(map(str, label_encoder.classes_))\n",
    "\n",
    "# Iterate through each classifier\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train_pca, y_train_encoded)\n",
    "    \n",
    "    # Validate on validation set\n",
    "    y_val_pred = clf.predict(X_val_pca)\n",
    "    val_accuracy = accuracy_score(y_val_encoded, y_val_pred)\n",
    "    \n",
    "    # Test on test set\n",
    "    y_test_pred = clf.predict(X_test_pca)\n",
    "    test_accuracy = accuracy_score(y_test_encoded, y_test_pred)\n",
    "    \n",
    "    # Generate classification report for the test set\n",
    "    report = classification_report(y_test_encoded, y_test_pred, target_names=class_names)\n",
    "    \n",
    "    # Confusion matrix for the test set\n",
    "    confusion = confusion_matrix(y_test_encoded, y_test_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        'Validation Accuracy': val_accuracy * 100,\n",
    "        'Test Accuracy': test_accuracy * 100,\n",
    "        'Classification Report': report,\n",
    "        'Confusion Matrix': confusion\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{name} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"{name} - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Classification Report (Test Set) for {name}:\\n\", report)\n",
    "    print(f\"Confusion Matrix (Test Set) for {name}:\\n\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Add Naive Bayes and SVM variations to the classifiers dictionary\n",
    "classifiers.update({\n",
    "    'Gaussian Naive Bayes': GaussianNB(),\n",
    "    'Linear SVM': SVC(kernel='linear'),\n",
    "    'Quadratic SVM': SVC(kernel='poly', degree=2),\n",
    "    'Cubic SVM': SVC(kernel='poly', degree=3),\n",
    "    'Fine Gaussian SVM': SVC(kernel='rbf', gamma=0.75),\n",
    "    'Medium Gaussian SVM': SVC(kernel='rbf', gamma=3),\n",
    "    'Coarse Gaussian SVM': SVC(kernel='rbf', gamma=12),\n",
    "    'Fine KNN': KNeighborsClassifier(n_neighbors=1),\n",
    "    'Medium KNN': KNeighborsClassifier(n_neighbors=10),\n",
    "    'Weighted KNN': KNeighborsClassifier(n_neighbors=10, weights='distance')\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine Tree - Validation Accuracy: 92.68%\n",
      "Fine Tree - Test Accuracy: 94.66%\n",
      "Classification Report (Test Set) for Fine Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.94        56\n",
      "           1       0.98      0.96      0.97        52\n",
      "           2       0.94      0.94      0.94        52\n",
      "           3       0.90      0.98      0.94        46\n",
      "\n",
      "    accuracy                           0.95       206\n",
      "   macro avg       0.95      0.95      0.95       206\n",
      "weighted avg       0.95      0.95      0.95       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Fine Tree:\n",
      " [[51  0  1  4]\n",
      " [ 0 50  2  0]\n",
      " [ 1  1 49  1]\n",
      " [ 1  0  0 45]]\n",
      "\n",
      "Medium Tree - Validation Accuracy: 92.68%\n",
      "Medium Tree - Test Accuracy: 94.66%\n",
      "Classification Report (Test Set) for Medium Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94        56\n",
      "           1       0.96      0.98      0.97        52\n",
      "           2       0.96      0.90      0.93        52\n",
      "           3       0.92      0.98      0.95        46\n",
      "\n",
      "    accuracy                           0.95       206\n",
      "   macro avg       0.95      0.95      0.95       206\n",
      "weighted avg       0.95      0.95      0.95       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Medium Tree:\n",
      " [[52  0  1  3]\n",
      " [ 0 51  1  0]\n",
      " [ 2  2 47  1]\n",
      " [ 1  0  0 45]]\n",
      "\n",
      "Coarse Tree - Validation Accuracy: 89.27%\n",
      "Coarse Tree - Test Accuracy: 93.20%\n",
      "Classification Report (Test Set) for Coarse Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.84      0.90        56\n",
      "           1       0.98      0.96      0.97        52\n",
      "           2       0.86      0.94      0.90        52\n",
      "           3       0.92      1.00      0.96        46\n",
      "\n",
      "    accuracy                           0.93       206\n",
      "   macro avg       0.93      0.94      0.93       206\n",
      "weighted avg       0.94      0.93      0.93       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Coarse Tree:\n",
      " [[47  0  6  3]\n",
      " [ 0 50  2  0]\n",
      " [ 1  1 49  1]\n",
      " [ 0  0  0 46]]\n",
      "\n",
      "Linear Discriminant - Validation Accuracy: 93.17%\n",
      "Linear Discriminant - Test Accuracy: 92.72%\n",
      "Classification Report (Test Set) for Linear Discriminant:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        56\n",
      "           1       0.96      0.98      0.97        52\n",
      "           2       0.85      0.96      0.90        52\n",
      "           3       0.92      0.96      0.94        46\n",
      "\n",
      "    accuracy                           0.93       206\n",
      "   macro avg       0.93      0.93      0.93       206\n",
      "weighted avg       0.93      0.93      0.93       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Linear Discriminant:\n",
      " [[46  0  6  4]\n",
      " [ 0 51  1  0]\n",
      " [ 0  2 50  0]\n",
      " [ 0  0  2 44]]\n",
      "\n",
      "Quadratic Discriminant - Validation Accuracy: 95.61%\n",
      "Quadratic Discriminant - Test Accuracy: 97.57%\n",
      "Classification Report (Test Set) for Quadratic Discriminant:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        56\n",
      "           1       1.00      0.98      0.99        52\n",
      "           2       0.98      1.00      0.99        52\n",
      "           3       0.94      0.98      0.96        46\n",
      "\n",
      "    accuracy                           0.98       206\n",
      "   macro avg       0.98      0.98      0.98       206\n",
      "weighted avg       0.98      0.98      0.98       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Quadratic Discriminant:\n",
      " [[53  0  0  3]\n",
      " [ 0 51  1  0]\n",
      " [ 0  0 52  0]\n",
      " [ 1  0  0 45]]\n",
      "\n",
      "Gaussian Naive Bayes - Validation Accuracy: 90.73%\n",
      "Gaussian Naive Bayes - Test Accuracy: 96.60%\n",
      "Classification Report (Test Set) for Gaussian Naive Bayes:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        56\n",
      "           1       1.00      0.96      0.98        52\n",
      "           2       0.98      0.98      0.98        52\n",
      "           3       0.94      0.98      0.96        46\n",
      "\n",
      "    accuracy                           0.97       206\n",
      "   macro avg       0.97      0.97      0.97       206\n",
      "weighted avg       0.97      0.97      0.97       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Gaussian Naive Bayes:\n",
      " [[53  0  0  3]\n",
      " [ 1 50  1  0]\n",
      " [ 1  0 51  0]\n",
      " [ 1  0  0 45]]\n",
      "\n",
      "Linear SVM - Validation Accuracy: 93.66%\n",
      "Linear SVM - Test Accuracy: 93.20%\n",
      "Classification Report (Test Set) for Linear SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.88        56\n",
      "           1       1.00      0.98      0.99        52\n",
      "           2       0.86      0.96      0.91        52\n",
      "           3       0.98      0.93      0.96        46\n",
      "\n",
      "    accuracy                           0.93       206\n",
      "   macro avg       0.94      0.93      0.93       206\n",
      "weighted avg       0.93      0.93      0.93       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Linear SVM:\n",
      " [[48  0  7  1]\n",
      " [ 0 51  1  0]\n",
      " [ 2  0 50  0]\n",
      " [ 3  0  0 43]]\n",
      "\n",
      "Quadratic SVM - Validation Accuracy: 27.80%\n",
      "Quadratic SVM - Test Accuracy: 30.58%\n",
      "Classification Report (Test Set) for Quadratic SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.44        56\n",
      "           1       0.00      0.00      0.00        52\n",
      "           2       0.70      0.13      0.23        52\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.31       206\n",
      "   macro avg       0.25      0.28      0.17       206\n",
      "weighted avg       0.25      0.31      0.18       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Quadratic SVM:\n",
      " [[56  0  0  0]\n",
      " [52  0  0  0]\n",
      " [45  0  7  0]\n",
      " [43  0  3  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cubic SVM - Validation Accuracy: 27.32%\n",
      "Cubic SVM - Test Accuracy: 28.16%\n",
      "Classification Report (Test Set) for Cubic SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.46        56\n",
      "           1       0.12      0.04      0.06        52\n",
      "           2       0.00      0.00      0.00        52\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.28       206\n",
      "   macro avg       0.10      0.26      0.13       206\n",
      "weighted avg       0.11      0.28      0.14       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Cubic SVM:\n",
      " [[56  0  0  0]\n",
      " [50  2  0  0]\n",
      " [42 10  0  0]\n",
      " [42  4  0  0]]\n",
      "\n",
      "Fine Gaussian SVM - Validation Accuracy: 64.88%\n",
      "Fine Gaussian SVM - Test Accuracy: 63.11%\n",
      "Classification Report (Test Set) for Fine Gaussian SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.84      0.66        56\n",
      "           1       0.65      0.67      0.66        52\n",
      "           2       0.57      0.38      0.46        52\n",
      "           3       0.90      0.61      0.73        46\n",
      "\n",
      "    accuracy                           0.63       206\n",
      "   macro avg       0.67      0.63      0.63       206\n",
      "weighted avg       0.66      0.63      0.63       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Fine Gaussian SVM:\n",
      " [[47  3  3  3]\n",
      " [ 5 35 12  0]\n",
      " [16 16 20  0]\n",
      " [18  0  0 28]]\n",
      "\n",
      "Medium Gaussian SVM - Validation Accuracy: 51.22%\n",
      "Medium Gaussian SVM - Test Accuracy: 50.00%\n",
      "Classification Report (Test Set) for Medium Gaussian SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.95      0.53        56\n",
      "           1       0.88      0.54      0.67        52\n",
      "           2       0.62      0.25      0.36        52\n",
      "           3       1.00      0.20      0.33        46\n",
      "\n",
      "    accuracy                           0.50       206\n",
      "   macro avg       0.72      0.48      0.47       206\n",
      "weighted avg       0.70      0.50      0.48       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Medium Gaussian SVM:\n",
      " [[53  0  3  0]\n",
      " [19 28  5  0]\n",
      " [35  4 13  0]\n",
      " [37  0  0  9]]\n",
      "\n",
      "Coarse Gaussian SVM - Validation Accuracy: 31.22%\n",
      "Coarse Gaussian SVM - Test Accuracy: 31.55%\n",
      "Classification Report (Test Set) for Coarse Gaussian SVM:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.96      0.43        56\n",
      "           1       1.00      0.13      0.24        52\n",
      "           2       0.67      0.08      0.14        52\n",
      "           3       0.00      0.00      0.00        46\n",
      "\n",
      "    accuracy                           0.32       206\n",
      "   macro avg       0.49      0.29      0.20       206\n",
      "weighted avg       0.50      0.32      0.21       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Coarse Gaussian SVM:\n",
      " [[54  0  2  0]\n",
      " [45  7  0  0]\n",
      " [48  0  4  0]\n",
      " [46  0  0  0]]\n",
      "\n",
      "Fine KNN - Validation Accuracy: 71.22%\n",
      "Fine KNN - Test Accuracy: 66.50%\n",
      "Classification Report (Test Set) for Fine KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.77      0.77        56\n",
      "           1       0.58      0.67      0.62        52\n",
      "           2       0.58      0.54      0.56        52\n",
      "           3       0.74      0.67      0.70        46\n",
      "\n",
      "    accuracy                           0.67       206\n",
      "   macro avg       0.67      0.66      0.66       206\n",
      "weighted avg       0.67      0.67      0.67       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Fine KNN:\n",
      " [[43  3  2  8]\n",
      " [ 2 35 14  1]\n",
      " [ 2 20 28  2]\n",
      " [ 9  2  4 31]]\n",
      "\n",
      "Medium KNN - Validation Accuracy: 57.56%\n",
      "Medium KNN - Test Accuracy: 51.94%\n",
      "Classification Report (Test Set) for Medium KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.71      0.70        56\n",
      "           1       0.40      0.48      0.43        52\n",
      "           2       0.47      0.42      0.44        52\n",
      "           3       0.53      0.43      0.48        46\n",
      "\n",
      "    accuracy                           0.52       206\n",
      "   macro avg       0.52      0.51      0.51       206\n",
      "weighted avg       0.52      0.52      0.52       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Medium KNN:\n",
      " [[40  5  3  8]\n",
      " [ 9 25 14  4]\n",
      " [ 3 21 22  6]\n",
      " [ 6 12  8 20]]\n",
      "\n",
      "Weighted KNN - Validation Accuracy: 70.24%\n",
      "Weighted KNN - Test Accuracy: 59.71%\n",
      "Classification Report (Test Set) for Weighted KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.71      0.75        56\n",
      "           1       0.48      0.56      0.52        52\n",
      "           2       0.49      0.46      0.48        52\n",
      "           3       0.65      0.65      0.65        46\n",
      "\n",
      "    accuracy                           0.60       206\n",
      "   macro avg       0.60      0.60      0.60       206\n",
      "weighted avg       0.60      0.60      0.60       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Weighted KNN:\n",
      " [[40  4  4  8]\n",
      " [ 3 29 17  3]\n",
      " [ 2 21 24  5]\n",
      " [ 6  6  4 30]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Muhammad Umar\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Iterate through each new classifier\n",
    "for name, clf in classifiers.items():\n",
    "    # Train the classifier\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Validate on validation set\n",
    "    y_val_pred = clf.predict(X_val_pca)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    # Convert class indices back to strings (or use actual class names if available)\n",
    "    class_names = list(map(str, label_encoder.classes_))\n",
    "    # Test on test set\n",
    "    y_test_pred = clf.predict(X_test_pca)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Generate classification report for the test set\n",
    "    report = classification_report(y_test, y_test_pred, target_names=class_names)\n",
    "    \n",
    "    # Confusion matrix for the test set\n",
    "    confusion = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[name] = {\n",
    "        'Validation Accuracy': val_accuracy * 100,\n",
    "        'Test Accuracy': test_accuracy * 100,\n",
    "        'Classification Report': report,\n",
    "        'Confusion Matrix': confusion\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{name} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"{name} - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Classification Report (Test Set) for {name}:\\n\", report)\n",
    "    print(f\"Confusion Matrix (Test Set) for {name}:\\n\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble Bagged Tree - Validation Accuracy: 97.56%\n",
      "Ensemble Bagged Tree - Test Accuracy: 98.54%\n",
      "Classification Report (Test Set) for Ensemble Bagged Tree:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        56\n",
      "           1       1.00      0.98      0.99        52\n",
      "           2       0.98      1.00      0.99        52\n",
      "           3       0.98      0.98      0.98        46\n",
      "\n",
      "    accuracy                           0.99       206\n",
      "   macro avg       0.99      0.99      0.99       206\n",
      "weighted avg       0.99      0.99      0.99       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Ensemble Bagged Tree:\n",
      " [[55  0  0  1]\n",
      " [ 0 51  1  0]\n",
      " [ 0  0 52  0]\n",
      " [ 1  0  0 45]]\n",
      "\n",
      "Ensemble Subspace Discriminant - Validation Accuracy: 82.44%\n",
      "Ensemble Subspace Discriminant - Test Accuracy: 83.50%\n",
      "Classification Report (Test Set) for Ensemble Subspace Discriminant:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77        56\n",
      "           1       0.85      1.00      0.92        52\n",
      "           2       0.86      0.94      0.90        52\n",
      "           3       0.93      0.59      0.72        46\n",
      "\n",
      "    accuracy                           0.83       206\n",
      "   macro avg       0.85      0.83      0.83       206\n",
      "weighted avg       0.84      0.83      0.83       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Ensemble Subspace Discriminant:\n",
      " [[44  7  3  2]\n",
      " [ 0 52  0  0]\n",
      " [ 1  2 49  0]\n",
      " [14  0  5 27]]\n",
      "\n",
      "Ensemble Subspace KNN - Validation Accuracy: 90.73%\n",
      "Ensemble Subspace KNN - Test Accuracy: 91.75%\n",
      "Classification Report (Test Set) for Ensemble Subspace KNN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.93      0.92        56\n",
      "           1       0.89      0.94      0.92        52\n",
      "           2       0.91      0.92      0.91        52\n",
      "           3       0.98      0.87      0.92        46\n",
      "\n",
      "    accuracy                           0.92       206\n",
      "   macro avg       0.92      0.92      0.92       206\n",
      "weighted avg       0.92      0.92      0.92       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Ensemble Subspace KNN:\n",
      " [[52  2  1  1]\n",
      " [ 1 49  2  0]\n",
      " [ 0  4 48  0]\n",
      " [ 4  0  2 40]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Define Ensemble methods with the correct 'estimator' argument\n",
    "ensemble_classifiers = {\n",
    "    'Ensemble Bagged Tree': BaggingClassifier(estimator=DecisionTreeClassifier(max_features='sqrt'), n_estimators=30, max_samples=0.9),\n",
    "    'Ensemble Subspace Discriminant': BaggingClassifier(estimator=LinearDiscriminantAnalysis(), n_estimators=30, max_features=0.3),\n",
    "    'Ensemble Subspace KNN': BaggingClassifier(estimator=KNeighborsClassifier(n_neighbors=5), n_estimators=30, max_features=0.5),\n",
    "}\n",
    "class_names = list(map(str, label_encoder.classes_))\n",
    "\n",
    "# Train and evaluate each ensemble method\n",
    "for name, clf in ensemble_classifiers.items():\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Evaluate on validation and test sets\n",
    "    y_val_pred = clf.predict(X_val_pca)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test_pca)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_test_pred, target_names=class_names)\n",
    "    confusion = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\n{name} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"{name} - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Classification Report (Test Set) for {name}:\\n\", report)\n",
    "    print(f\"Confusion Matrix (Test Set) for {name}:\\n\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Narrow NN - Validation Accuracy: 82.44%\n",
      "Narrow NN - Test Accuracy: 81.55%\n",
      "Classification Report (Test Set) for Narrow NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.93      0.81        56\n",
      "           1       0.87      0.87      0.87        52\n",
      "           2       0.81      0.81      0.81        52\n",
      "           3       1.00      0.63      0.77        46\n",
      "\n",
      "    accuracy                           0.82       206\n",
      "   macro avg       0.85      0.81      0.81       206\n",
      "weighted avg       0.84      0.82      0.81       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Narrow NN:\n",
      " [[52  1  3  0]\n",
      " [ 0 45  7  0]\n",
      " [ 4  6 42  0]\n",
      " [17  0  0 29]]\n",
      "\n",
      "Medium NN - Validation Accuracy: 73.66%\n",
      "Medium NN - Test Accuracy: 73.79%\n",
      "Classification Report (Test Set) for Medium NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.75      0.72        56\n",
      "           1       0.69      1.00      0.82        52\n",
      "           2       0.69      0.56      0.62        52\n",
      "           3       1.00      0.63      0.77        46\n",
      "\n",
      "    accuracy                           0.74       206\n",
      "   macro avg       0.77      0.73      0.73       206\n",
      "weighted avg       0.76      0.74      0.73       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Medium NN:\n",
      " [[42  1 13  0]\n",
      " [ 0 52  0  0]\n",
      " [ 1 22 29  0]\n",
      " [17  0  0 29]]\n",
      "\n",
      "Wide NN - Validation Accuracy: 77.07%\n",
      "Wide NN - Test Accuracy: 75.73%\n",
      "Classification Report (Test Set) for Wide NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        56\n",
      "           1       0.85      0.88      0.87        52\n",
      "           2       0.64      0.85      0.73        52\n",
      "           3       1.00      0.52      0.69        46\n",
      "\n",
      "    accuracy                           0.76       206\n",
      "   macro avg       0.80      0.75      0.75       206\n",
      "weighted avg       0.79      0.76      0.75       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Wide NN:\n",
      " [[42  1 13  0]\n",
      " [ 0 46  6  0]\n",
      " [ 1  7 44  0]\n",
      " [16  0  6 24]]\n",
      "\n",
      "Bilayered NN - Validation Accuracy: 80.49%\n",
      "Bilayered NN - Test Accuracy: 79.13%\n",
      "Classification Report (Test Set) for Bilayered NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.91      0.77        56\n",
      "           1       0.82      0.98      0.89        52\n",
      "           2       0.97      0.56      0.71        52\n",
      "           3       0.86      0.70      0.77        46\n",
      "\n",
      "    accuracy                           0.79       206\n",
      "   macro avg       0.83      0.79      0.79       206\n",
      "weighted avg       0.82      0.79      0.79       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Bilayered NN:\n",
      " [[51  2  0  3]\n",
      " [ 0 51  1  0]\n",
      " [12  9 29  2]\n",
      " [14  0  0 32]]\n",
      "\n",
      "Trilayered NN - Validation Accuracy: 76.59%\n",
      "Trilayered NN - Test Accuracy: 77.18%\n",
      "Classification Report (Test Set) for Trilayered NN:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.80      0.81        56\n",
      "           1       0.67      1.00      0.80        52\n",
      "           2       0.78      0.48      0.60        52\n",
      "           3       0.90      0.80      0.85        46\n",
      "\n",
      "    accuracy                           0.77       206\n",
      "   macro avg       0.79      0.77      0.76       206\n",
      "weighted avg       0.79      0.77      0.76       206\n",
      "\n",
      "Confusion Matrix (Test Set) for Trilayered NN:\n",
      " [[45  2  5  4]\n",
      " [ 0 52  0  0]\n",
      " [ 3 24 25  0]\n",
      " [ 7  0  2 37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Define Neural Networks configurations\n",
    "nn_classifiers = {\n",
    "    'Narrow NN': MLPClassifier(hidden_layer_sizes=(25,), max_iter=1000, activation='relu', solver='adam'),\n",
    "    'Medium NN': MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000, activation='relu', solver='adam'),\n",
    "    'Wide NN': MLPClassifier(hidden_layer_sizes=(200,), max_iter=1000, activation='relu', solver='adam'),\n",
    "    'Bilayered NN': MLPClassifier(hidden_layer_sizes=(15, 20), max_iter=1000, activation='relu', solver='adam'),\n",
    "    'Trilayered NN': MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=1000, activation='relu', solver='adam'),\n",
    "}\n",
    "class_names = list(map(str, label_encoder.classes_))\n",
    "\n",
    "# Train and evaluate each neural network\n",
    "for name, clf in nn_classifiers.items():\n",
    "    clf.fit(X_train_pca, y_train)\n",
    "    \n",
    "    # Evaluate on validation and test sets\n",
    "    y_val_pred = clf.predict(X_val_pca)\n",
    "    val_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "    \n",
    "    y_test_pred = clf.predict(X_test_pca)\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    # Classification report and confusion matrix\n",
    "    report = classification_report(y_test, y_test_pred, target_names=class_names)\n",
    "    confusion = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    print(f\"\\n{name} - Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "    print(f\"{name} - Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "    print(f\"Classification Report (Test Set) for {name}:\\n\", report)\n",
    "    print(f\"Confusion Matrix (Test Set) for {name}:\\n\", confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
